# GRiST Meeting Pipeline

AWS SAM application for processing meeting transcripts using Step Functions, Lambda, and Amazon Bedrock.

## Overview

This pipeline converts raw meeting transcripts into structured outputs using **intelligent sliding window chunking** for optimal quality:

### Output Files
1. **turns.json** - Atomic turns with speaker identification and timestamps
2. **qa_pairs.json** - Grouped Q&A exchanges and discussions  
3. **minutes.json** - Formal meeting minutes with action items
4. **summaries.json** - Executive and detailed summaries
5. **events.ics** - Calendar events extracted from meeting content
6. **manifest.json** - Processing metadata and quality metrics

### Sliding Window Chunking ðŸŽ¯

For transcripts >50K tokens, the pipeline automatically:
- **Splits** transcript into ~15K token overlapping chunks (2K overlap)
- **Processes** chunks in parallel via Step Functions Map state
- **Merges** results intelligently, deduplicating overlaps
- **Benefits**: Better speaker tracking, turn boundaries, Q&A coherence, parallel processing

```
Chunk 1: [===============]
                    [===============] Chunk 2
                              [===============] Chunk 3
         â””â”€â”€ 2K overlap â”€â”€â”˜
```

## Architecture

- **AWS SAM** - Infrastructure as Code
- **Step Functions** - Orchestration workflow
- **Lambda** - Processing functions (Python 3.12)
- **Amazon Bedrock** - LLM inference using Claude Sonnet
- **S3** - Storage for inputs and outputs
- **EventBridge** - Automatic trigger on file upload

### Event Flow

1. **Upload** - Transcript (.txt) uploaded to S3 bucket
2. **EventBridge** - Detects S3 "Object Created" event
3. **Trigger Lambda** - Extracts meeting info and starts Step Functions
4. **Chunking** - Splits large transcripts into overlapping segments
5. **Parallel Processing** - Map state processes chunks simultaneously
6. **Merge** - Intelligently combines chunks, deduplicating overlaps
7. **Analysis Pipeline** - Four parallel processing branches (Q&A, Minutes, Summaries, Calendar)
8. **Manifest** - Collects metadata and creates final manifest
9. **Output** - All results saved to S3 in meeting-specific folder

### Processing Steps

```
S3 Upload â†’ EventBridge â†’ Trigger Lambda â†’ Step Functions:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 1. ChunkTranscript (auto-splits if >50K tokens)             â”‚
  â”‚    â””â”€> Creates overlapping chunks with metadata             â”‚
  â”‚                                                              â”‚
  â”‚ 2. ProcessChunks (Map State - parallel)                     â”‚
  â”‚    â”œâ”€> PreprocessTurns (Chunk 1) â”€â”                         â”‚
  â”‚    â”œâ”€> PreprocessTurns (Chunk 2) â”€â”¤                         â”‚
  â”‚    â”œâ”€> PreprocessTurns (Chunk 3) â”€â”¼â”€> All chunks in ||      â”‚
  â”‚    â””â”€> PreprocessTurns (Chunk N) â”€â”˜                         â”‚
  â”‚                                                              â”‚
  â”‚ 3. MergeChunks                                               â”‚
  â”‚    â””â”€> Intelligent deduplication of overlaps                â”‚
  â”‚                                                              â”‚
  â”‚ 4. ParallelProcessing (4 branches)                           â”‚
  â”‚    â”œâ”€> GroupQA                                               â”‚
  â”‚    â”œâ”€> MinutesActions                                        â”‚
  â”‚    â”œâ”€> Summarize                                             â”‚
  â”‚    â””â”€> MakeIcs                                               â”‚
  â”‚                                                              â”‚
  â”‚ 5. MakeManifest                                              â”‚
  â”‚    â””â”€> Collects all outputs and metadata                    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
â”œâ”€â”€ template.yaml              # SAM template
â”œâ”€â”€ statemachine.asl.json      # Step Functions definition
â”œâ”€â”€ prompts/                   # LLM prompt templates
â”‚   â”œâ”€â”€ 01_turns.md
â”‚   â”œâ”€â”€ 02_qa_grouper.md  
â”‚   â”œâ”€â”€ 03_minutes_actions.md
â”‚   â”œâ”€â”€ 04_summaries.md
â”‚   â”œâ”€â”€ 05_ics.md
â”‚   â””â”€â”€ 06_manifest.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/               # Shared utilities
â”‚   â”‚   â”œâ”€â”€ bedrock_client.py
â”‚   â”‚   â”œâ”€â”€ s3io.py
â”‚   â”‚   â””â”€â”€ json_utils.py
â”‚   â”œâ”€â”€ handlers/             # Lambda functions
â”‚   â”‚   â”œâ”€â”€ chunk_transcript.py    # ðŸ†• Split into overlapping chunks
â”‚   â”‚   â”œâ”€â”€ merge_chunks.py        # ðŸ†• Intelligent chunk merging
â”‚   â”‚   â”œâ”€â”€ preprocess_turns.py
â”‚   â”‚   â”œâ”€â”€ group_qa.py
â”‚   â”‚   â”œâ”€â”€ minutes_actions.py
â”‚   â”‚   â”œâ”€â”€ summarize.py
â”‚   â”‚   â”œâ”€â”€ make_ics.py
â”‚   â”‚   â”œâ”€â”€ make_manifest.py
â”‚   â”‚   â””â”€â”€ trigger_pipeline.py    # EventBridge handler
â”‚   â””â”€â”€ models/               # Type definitions
â”‚       â”œâ”€â”€ types.py
â”‚       â””â”€â”€ schemas.py
â””â”€â”€ tests/                    # Unit tests
    â”œâ”€â”€ test_smoke.py
    â””â”€â”€ test_chunking.py      # ðŸ†• Chunking & merge tests
```

## Environment Variables

- `BUCKET` - S3 bucket for storing files
- `REGION` - AWS region (default: us-east-1)  
- `TIME_ZONE` - Meeting timezone (default: America/New_York)
- `INFERENCE_PROFILE_ARN` - Bedrock inference profile ARN

## Setup & Deployment

### Prerequisites
- AWS CLI configured
- SAM CLI installed  
- Python 3.12
- S3 bucket with EventBridge notifications enabled

### Enable EventBridge on S3 Bucket (One-Time Setup)

âœ… **You already did this!** But for reference:

```bash
aws s3api put-bucket-notification-configuration \
  --bucket mtg-analyzer-grist-2210 \
  --notification-configuration '{"EventBridgeConfiguration": {}}'
```

### Build & Deploy

```bash
# Build the application
sam build

# Deploy (first time - will prompt for confirmations)
sam deploy --guided

# Subsequent deployments
sam deploy
```

### Local Testing

```bash
# Validate imports and project structure
python test_local.py

# Run unit tests
python -m pytest tests/
```

## Usage

### Automatic Processing (Recommended) ðŸš€

Simply upload a .txt transcript file to S3 - the pipeline starts automatically!

```bash
# Upload anywhere in the bucket - auto-organizes by filename
aws s3 cp meeting_transcript.txt s3://mtg-analyzer-grist-2210/GMT20251022-club-meeting.txt

# Or organize manually by date
aws s3 cp transcript.txt s3://mtg-analyzer-grist-2210/meetings/2025-10-22/transcript.txt
```

**What happens next:**
1. EventBridge detects the upload
2. `TriggerPipelineFn` extracts meeting info from path/filename
3. Step Functions pipeline starts automatically
4. All outputs saved to `meetings/{meeting-id}/` folder

### Manual Trigger (If Needed)

Start Step Functions execution manually:

```bash
STATE_MACHINE_ARN=$(aws cloudformation describe-stacks \
  --stack-name mtg-analyzer \
  --query "Stacks[0].Outputs[?OutputKey=='MeetingPipelineStateMachineArn'].OutputValue" \
  --output text)

aws stepfunctions start-execution \
  --state-machine-arn $STATE_MACHINE_ARN \
  --input '{
    "meeting_id": "grist-2025-10-22",
    "input_key": "GMT20251021-224835_Recording.txt",
    "output_key": "meetings/grist-2025-10-22/"
  }'
```

### Monitor Execution

```bash
# List recent executions
aws stepfunctions list-executions --state-machine-arn $STATE_MACHINE_ARN

# Tail trigger function logs
sam logs --stack-name mtg-analyzer --name TriggerPipelineFn --tail

# View specific Lambda logs
aws logs tail /aws/lambda/mtg-analyzer-PreprocessTurnsFn --follow
```

### Retrieve Results

```bash
# List all outputs for a meeting
aws s3 ls s3://mtg-analyzer-grist-2210/meetings/grist-2025-10-22/

# Download specific output
aws s3 cp s3://mtg-analyzer-grist-2210/meetings/grist-2025-10-22/manifest.json .
```

## Development

### Chunking Strategy

**Why Chunk?** Even when transcripts fit in Claude's 200K context window, chunking provides:
- âœ… **Better Quality**: Focused analysis per chunk vs. overwhelming context
- âœ… **Speaker Consistency**: Overlap regions ensure continuous speaker tracking
- âœ… **Turn Boundaries**: Natural breaks prevent cutting mid-conversation
- âœ… **Parallel Processing**: Multiple chunks process simultaneously (faster)
- âœ… **Resilience**: One chunk failure doesn't kill entire pipeline

**Chunking Parameters** (in `chunk_transcript.py`):
- `chunk_size_tokens`: 15,000 (target size per chunk)
- `overlap_tokens`: 2,000 (overlap between adjacent chunks)
- `threshold`: 50,000 tokens (auto-chunk if transcript exceeds)

**Smart Boundary Detection**: 
Chunks break at natural points (paragraphs â†’ lines â†’ sentences) rather than mid-word.

**Deduplication Logic** (in `merge_chunks.py`):
- Compares turns via Jaccard similarity on normalized text
- Threshold: 0.75 similarity = duplicate
- Takes longer text when merging duplicates
- Searches only within overlap region (efficient)

### Adding New Handlers
1. Create handler in `src/handlers/`
2. Add to `template.yaml` 
3. Update `statemachine.asl.json`
4. Add corresponding prompt in `prompts/`

### Type Safety
All functions use Python type hints with TypedDict definitions in `src/models/types.py`.

### Validation
JSON schema validation is performed using definitions in `src/models/schemas.py`.

## Monitoring

- CloudWatch Logs for Lambda functions
- Step Functions execution history
- S3 bucket metrics for storage usage

## Security

- Least-privilege IAM roles
- VPC endpoints for AWS service communication
- Encryption at rest for S3 storage